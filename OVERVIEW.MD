The MedGemma Impact Challenge
Build human-centered AI applications with MedGemma and other open models from Google’s Health AI Developer Foundations (HAI-DEF).
The MedGemma Impact Challenge
In this competition, you’ll use MedGemma and other open models from Google’s Health AI Developer Foundations (HAI-DEF) to build human-centered AI applications.
# AI is already reshaping medicine, from diagnostics to drug discovery. But many clinical environments can’t rely on large, closed models that require constant internet access or centralized infrastructure. They need adaptable, privacy-focused tools that can run anywhere care is delivered.

To meet this need, Google has released open-weight models specifically designed to help developers more efficiently create novel healthcare and life sciences applications. MedGemma and the rest of HAI-DEF collection give developers a starting point for building powerful tools while allowing them full control over the models and associated infrastructure.

In this competition, you’ll use these models to build full fledged demonstration applications. Whether you’re building apps to streamline workflows, support patient communication, or facilitate diagnostics, your solution should demonstrate how these tools can enhance healthcare.

Evaluation
Minimum requirements
To be considered a valid contribution, your submission should include:

a high-quality writeup describing use of a specific HAI-DEF model,
associated reproducible code for your initial results, and
a video for judging.
Your complete submission consists of a single package containing your video (3 minutes or less) and write-up (3 pages or less). This single entry can be submitted to the main competition track, and one special technology award, so separate submissions are not required. Read the section Submission Instructions for more details. Please follow the provided write-up template and refer to the judging criteria for all content requirements.

Evaluation Criteria
Submissions are evaluated on the following criteria:

Criteria (percentage)	Description
Effective use of HAI-DEF models
(20%)	Are HAI-DEF models used appropriately?

You will be assessed on: whether the submission proposes an application that uses HAI-DEF models to their fullest potential, where other solutions would likely be less effective.

Note: Use of at least one of HAI-DEF models such as MedGemma is mandatory.
Problem domain
(15%)	How important is this problem to solve and how plausible is it that AI is the right solution?

You will be assessed on: storytelling, clarity of problem definition, clarity on whether there is an unmet need, the magnitude of the problem, who the user is and their improved journey given your solution.
Impact potential
(15%)	If the solution works, what impact would it have?

You will be assessed on: clear articulation of real or anticipated impact of your application within the given problem domain and description of how you calculated your estimates.
Product feasibility
(20%)	Is the technical solution clearly feasible?

You will be assessed on: technical documentation detailing model fine-tuning, model's performance analysis, your user-facing application stack, deployment challenges and how you plan on overcoming them. Consideration of how a product might be used in practice, rather than only for benchmarking.
Execution and communication (30%)	What is the quality of your project's execution and your clear and concise communication of your work? Your main submission package follows the provided template and includes a mandatory video demo and a write-up with links to your source material.

You will be assessed on: the clarity, polish, and effectiveness of your video demonstration; the completeness and readability of your technical write-up; and the quality of your source code (e.g., organization, comments, reusability). Judges will look for a cohesive and compelling narrative across all submitted materials that effectively articulates how you meet the rest of the judging criteria.
Timeline
January 13, 2026 - Start Date.
February 24, 2026 - Final Submission Deadline.
March 17 - 24, 2026 - Anticipated Results Announcement - Time required to evaluate results is dependent on the number of submissions.
All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.

Judges
Fereshteh Mahvar
Staff Medical Software Engineer & Solutions Architect, Google Health AI
Omar Sanseviero
Developer Experience Lead, Google DeepMind
Glenn Cameron
Sr. PMM, Google
Can "John" Kirmizi
Software Engineer, Google Research
Andrew Sellergren
Software Engineer, Google Research
Dave Steiner
Clinical Research Scientist, Google
Sunny Virmani
Group Product Manager, Google Research
Liron Yatziv
Research Engineer, Google Research
Daniel Golden
Engineering Manager, Google Research
Yun Liu
Research Scientist, Google Research
Rebecca Hemenway
Health AI Strategic Partnerships, Google Research
Fayaz Jamil
Technical Program Manager, Google Research
Tracks and Awards
Main Track · $75,000
Description
These prizes are awarded to the best overall projects that demonstrate exceptional vision, technical execution, and potential for real-world impact.

Track Awards

1st Place
$30,000

2nd Place
$20,000

3rd Place
$15,000

4th Place
$10,000
Agentic Workflow Prize · $10,000
Description
It is awarded for the project that most effectively reimagines a complex workflow by deploying HAI-DEF models as intelligent agents or callable tools. The winning solution will demonstrate a significant overhaul of a challenging process, showcasing the power of agentic AI to improve efficiency and outcomes.

Track Awards

Agentic Workflow Prize 1
$5,000

Agentic Workflow Prize 2
$5,000
The Novel Task Prize · $10,000
Description
Awarded for the most impressive fine-tuned model that successfully adapts a HAI-DEF model to perform a useful task for which it was not originally trained on pre-release.

Track Awards

The Novel Task Prize 1
$5,000

The Novel Task Prize 2
$5,000
The Edge AI Prize · $5,000
Description
This prize is awarded to the most impressive solution that brings AI out of the cloud and into the field. It will be awarded to the team that best adapts a HAI-DEF model to run effectively on a local device like a mobile phone, portable scanner, lab instrument, or other edge hardware.

Track Awards

The Edge AI Prize
$5,000
Submission Instructions
Your submission must be a Kaggle Writeup and it must be attached to this page. To create a new Writeup, click on the "New Writeup" button here. After you have saved your Writeup, you should see a "Submit" button in the top right corner. Each team is limited to submitting only a single Writeup, but that same Writeup can be un-submitted, edited, and re-submitted as many times as you'd like. Your Writeup should contain a summary of your overall project along with links to supporting resources.

Choosing a track
All submissions compete in the Main Track, and are eligible to win one special award prize (Agentic Workflow Prize, The Novel Task Prize, or The Edge of AI Prize). While you will have the option to select multiple tracks when you create your writeup, you can only chose the main track and one special award prize. If you choose multiple special awards, we will only consider your submission for one of your indicated special awards (randomly selected).

Links
Required: Video (3 min or less)
Required: Public code repository
Bonus: Public interactive live demo app
Bonus: Open-weight Hugging Face model tracing to a HAI-DEF model
Proposed Writeup template
Use the following structure and in 3 pages or less present your work. Less is more! You should take advantage of the video to convey most of the concepts and keep the write-up as high level as possible.

### Project name 
[A concise name for your project.]

### Your team 
Sanjid Hasan,Sakib Hassan

### Problem statement
[Your answer to the “Problem domain” & “Impact potential” criteria]

### Overall solution: 
[Your answer to “Effective use of HAI-DEF models” criterion] 

### Technical details 
[Your answer to “Product feasibility” criterion]
Note: If you attach a private Kaggle Resource to your public Kaggle Writeup, your private Resource will automatically be made public after the deadline.

Citation
Fereshteh Mahvar, Yun Liu, Daniel Golden, Fayaz Jamil, Sunny Jansen, Can Kirmizi, Rory Pilgrim, David F. Steiner, Andrew Sellergren, Richa Tiwari, Sunny Virmani, Liron Yatziv, Rebecca Hemenway, Yossi Matias, Ronit Levavi Morad, Avinatan Hassidim, Shravya Shetty, and María Cruz. The MedGemma Impact Challenge. https://kaggle.com/competitions/med-gemma-impact-challenge, 2026. Kaggle.
